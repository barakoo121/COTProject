# CoT Optimization Project

A Chain of Thought (CoT) optimization system for language models using retrieval-augmented generation (RAG) with the CoT-Collection dataset.

## ğŸ¯ Project Overview

This project implements a three-phase pipeline to enhance language model reasoning through retrieval-augmented Chain of Thought prompting:

1. **Phase 1**: Build knowledge base from CoT-Collection dataset with embeddings and FAISS indexing
2. **Phase 2**: Implement retrieval pipeline for finding similar reasoning examples  
3. **Phase 3**: Generate responses using baseline vs CoT comparison methodology

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phase 1       â”‚    â”‚   Phase 2       â”‚    â”‚   Phase 3       â”‚
â”‚ Knowledge Base  â”‚â”€â”€â”€â–¶â”‚   Retrieval     â”‚â”€â”€â”€â–¶â”‚   Generation    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Dataset       â”‚    â”‚ â€¢ Query Encode  â”‚    â”‚ â€¢ Baseline      â”‚
â”‚ â€¢ Embeddings    â”‚    â”‚ â€¢ FAISS Search  â”‚    â”‚ â€¢ CoT w/ RAG    â”‚
â”‚ â€¢ FAISS Index   â”‚    â”‚ â€¢ Top-5 Examplesâ”‚    â”‚ â€¢ Comparison    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Project Structure

```
COTProject/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ phase1/              # Knowledge base creation
â”‚   â”‚   â”œâ”€â”€ dataset_processor.py    # CoT-Collection data processing
â”‚   â”‚   â”œâ”€â”€ embedding_generator.py  # Question embeddings (all-mpnet-base-v2)
â”‚   â”‚   â””â”€â”€ vector_indexer.py       # FAISS index creation/management
â”‚   â”œâ”€â”€ phase2/              # Retrieval pipeline
â”‚   â”‚   â””â”€â”€ retrieval_pipeline.py   # Query processing & example retrieval
â”‚   â”œâ”€â”€ phase3/              # Generation pipeline
â”‚   â”‚   â””â”€â”€ generation_pipeline.py  # T5 baseline vs CoT comparison
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ config_loader.py        # Configuration management
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml          # System configuration
â”œâ”€â”€ tests/                   # Test files and debugging scripts
â”œâ”€â”€ data/                    # Local data (git-ignored)
â”‚   â”œâ”€â”€ processed/           # Processed datasets and embeddings
â”‚   â”œâ”€â”€ faiss_index/         # FAISS vector indices
â”‚   â””â”€â”€ cache/               # HuggingFace cache
â”œâ”€â”€ main.py                  # Main pipeline execution
â”œâ”€â”€ demo.py                  # Interactive demonstration
â””â”€â”€ requirements.txt         # Python dependencies
```

## ğŸš€ Key Features

### Phase 1: Knowledge Base Creation
- **Dataset Processing**: Loads CoT-Collection (1.8M examples), extracts question-rationale-answer triplets
- **Smart Embeddings**: Uses `all-mpnet-base-v2` to encode questions for semantic similarity
- **FAISS Indexing**: Creates efficient vector index for fast similarity search
- **Configurable Sampling**: Supports limiting dataset size for development/testing

### Phase 2: Retrieval Pipeline  
- **Semantic Search**: Finds top-5 most similar questions to user queries
- **Multi-format Output**: Simple, detailed, and prompt-ready formatting
- **Similarity Filtering**: Configurable similarity thresholds
- **CoT Prompt Generation**: Creates reasoning examples without answer leakage

### Phase 3: Generation Pipeline
- **Dual Methodology**: Baseline (direct) vs CoT (reasoning-guided) approaches
- **T5 Integration**: Uses T5 model for text generation
- **Retrieval-Augmented CoT**: Incorporates similar reasoning patterns
- **Performance Comparison**: Evaluates baseline vs enhanced reasoning

## ğŸ’¡ Chain of Thought Strategy

The system implements retrieval-augmented CoT reasoning:

1. **Query Analysis**: User asks "What is 25 Ã— 17?"
2. **Similar Example Retrieval**: Finds 5 similar math problems with step-by-step reasoning
3. **Prompt Construction**: Shows reasoning patterns without revealing answers
4. **Guided Generation**: Model follows demonstrated thinking patterns to solve new problem

### Example Prompt Structure:
```
Here are examples demonstrating how to think step-by-step:

Example 1:
Question: What is 12 Ã— 8?
Rationale: I need to multiply 12 by 8. I can break this down: 12 Ã— 8 = 12 Ã— (10 - 2) = (12 Ã— 10) - (12 Ã— 2) = 120 - 24 = 96.

[... 4 more examples ...]

---

Now, solve the following problem using the same step-by-step thinking:
What is 25 Ã— 17?
```

## ğŸ› ï¸ Technical Implementation

### Core Technologies
- **HuggingFace Transformers**: T5 model, sentence-transformers
- **FAISS**: Fast similarity search and clustering  
- **CoT-Collection Dataset**: 1.8M question-rationale-answer pairs
- **Sentence Transformers**: all-mpnet-base-v2 for embeddings

### Data Processing Pipeline
```python
# Simplified data flow
raw_data â†’ triplet_extraction â†’ question_embedding â†’ faiss_indexing
query â†’ query_embedding â†’ similarity_search â†’ prompt_construction â†’ generation
```

### Key Optimizations
- **Batch Processing**: Efficient embedding generation
- **Memory Management**: Configurable dataset sampling
- **Index Persistence**: Save/load FAISS indices
- **Path Resolution**: Robust configuration loading

## ğŸƒâ€â™‚ï¸ Quick Start

1. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

2. **Run Full Pipeline**:
   ```bash
   python main.py
   ```

3. **Interactive Demo**:
   ```bash
   python demo.py
   ```

4. **Test Individual Components**:
   ```bash
   python tests/test_5k_dataset.py
   python src/phase2/retrieval_pipeline.py
   ```

## ğŸ“Š Results & Evaluation

The system enables comparison between:
- **Baseline**: Direct question â†’ answer generation
- **CoT-RAG**: Question â†’ similar examples â†’ reasoning-guided generation

### Expected Improvements
- Enhanced reasoning quality through example-guided thinking
- Better step-by-step problem decomposition  
- Improved accuracy on complex reasoning tasks
- Consistent reasoning patterns across similar problem types

## ğŸ”§ Configuration

Key settings in `config/config.yaml`:
- **Dataset**: Sample size, processing options
- **Embeddings**: Model selection, batch size, device
- **Vector Index**: FAISS index type, similarity thresholds
- **Generation**: Model parameters, output formatting

## ğŸ¤ Development Notes

### Data Management
- Heavy data files (embeddings, indices) are git-ignored
- Data regenerated via pipeline execution
- Configurable sampling for development efficiency

### Testing Strategy
- Component-level tests for each phase
- Integration tests for full pipeline
- Sample data generation for rapid iteration
- Debug utilities for troubleshooting

### Performance Considerations
- CUDA support for GPU acceleration
- Batch processing for efficiency
- Configurable memory usage
- Index persistence for faster startup

## ğŸ“ Research Context

This implementation is based on Chain of Thought prompting research, specifically focusing on:
- Retrieval-augmented reasoning enhancement
- Example-guided problem solving
- Semantic similarity for reasoning pattern matching
- Large-scale reasoning dataset utilization (CoT-Collection)

## ğŸš€ Future Enhancements

- Multi-domain reasoning support
- Dynamic similarity threshold adjustment
- Advanced prompt engineering techniques
- Performance benchmarking against standard datasets
- Support for additional language models

---

**Built with â¤ï¸ for advancing AI reasoning capabilities**